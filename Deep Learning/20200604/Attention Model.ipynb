{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparing\n",
    "\n",
    "## ENGLISH -> KOREAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang1 = 'eng'\n",
    "lang2 = 'kor'\n",
    "input_lang = Lang(lang1)\n",
    "output_lang = Lang(lang2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일(전체) 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go.\\t가.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8363271 (Eunhee)', 'Hi.\\t안녕.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #8355888 (Eunhee)', 'Run!\\t뛰어!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #8355891 (Eunhee)', 'Run.\\t뛰어.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #8363273 (Eunhee)', 'Who?\\t누구?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #6820074 (yesjustryan)', 'Wow!\\t우와!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #8355878 (Eunhee)', 'Fire!\\t쏴!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #8355899 (Eunhee)', 'Help!\\t도와줘!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #8355885 (Eunhee)', 'Jump!\\t점프!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1102981 (jamessilver) & #8355893 (Eunhee)', 'Jump.\\t점프해.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #8355890 (Eunhee)']\n"
     ]
    }
   ],
   "source": [
    "lines = open('data/%s-%s.txt' %(lang1, lang2), encoding = 'utf-8').read().strip().split('\\n')\n",
    "print(lines[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go.', '가.'] ['Hi.', '안녕.']\n"
     ]
    }
   ],
   "source": [
    "print(lines[0].split('\\t')[:2], lines[1].split('\\t')[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 각 줄 별로 읽어서 대문자는 소문자로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go .', '가 .'], ['hi .', '안녕 .']]\n",
      "Read 3621 sentence pairs\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "for l in lines :\n",
    "    eng, kor = l.split('\\t')[:2]\n",
    "    kor = kor[:-1]+' .'\n",
    "    pairs.append([normalizeString(eng), kor])\n",
    "\n",
    "print(pairs[:2])\n",
    "\n",
    "# 읽어온 문장의 개수\n",
    "print(\"Read %s sentence pairs\" % len(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 읽어오는 영/한 문장에 대한 trimming \n",
    "- 각 문장이 10자가 넘으면 사용하지 않음 \n",
    "- encoder-decoder의 아키텍쳐 사이즈 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH \n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trimming 결과보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 3621 sentence pairs\n",
      "Trimmed to 3144 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2195\n",
      "kor 4545\n",
      "['stop crying .', '그만 울어 .']\n"
     ]
    }
   ],
   "source": [
    "print(\"Read %s sentence pairs\" % len(pairs))\n",
    "pairs = filterPairs(pairs)\n",
    "print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "print(\"Counting words...\")\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "print(\"Counted words:\")\n",
    "print(input_lang.name, input_lang.n_words)\n",
    "print(output_lang.name, output_lang.n_words)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Model\n",
    "\n",
    "### Encoder - Decoder network\n",
    "\n",
    "<img src=\"./image/seq2seq.png\" width=\"600\" height=\"200\">\n",
    "\n",
    "### LSTM and GRU(Gated Recurrent Unit)\n",
    "<img src=\"./image/rnnunit.png\" width=\"800\" height=\"300\">\n",
    "\n",
    "- LSTM : hidden state + memory cell\n",
    "\n",
    "- GRU : memory cell이 hidden state에 포함된 경량화된 모델\n",
    "\n",
    "$$h^{(t)} = u_t\\odot h^{(t-1)}+(1-u_t)\\odot\\sigma(b+W(r_t\\odot h^{(t-1)})+Ux^{(t)})$$\n",
    "$$u_t = \\sigma(b^u+W^uh^{(t-1)}+U^ux^{(t)})$$\n",
    "$$r_t = \\sigma(b^r+W^rh^{(t-1)}+U^rx^{(t)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # input size : 입력 문장의 길이\n",
    "        # hidden size : context vector의 차원\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # 처음 들어가는 hidden state\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Model\n",
    "\n",
    "<img src=\"./image/attention.jpg\" width=\"500\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        ## input embedding과 이전 hidden state를 이용해서 attention weight 구함\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        \n",
    "        ## encoder output에 위에서 구한 attention weight를 곱해서 weighted combination을 구함\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        ## input embedding과 context vector를 이용해서 예측하기\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Training Data\n",
    "\n",
    "## indexes From Sentence : \n",
    "- lang.word2index : laguage(한/영) 별로 word 별로 index가 저장되어있는 dictionary\n",
    "- 문장에서 각 단어의 index 를 순서대로 저장\n",
    "\n",
    "## tensor From Sentence :\n",
    "- 위 함수로 얻은 index list에 EOS 토큰을 마지막에 추가\n",
    "- tensor로 변환\n",
    "\n",
    "## tensors From Pair :\n",
    "- 한/영 문장 pair 에 대해 위 2개의 함수를 각각 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "\n",
    "## train : 매 iteration 반복되는 학습과정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainIters  \n",
    "- SGD 이용 \n",
    "- n epochs\n",
    "- train_pairs : n번의 epoch에서 사용할 각각 샘플 1개씩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "    \n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 18s (- 29m 45s) (5000 10%) 4.6007\n",
      "6m 39s (- 26m 37s) (10000 20%) 3.6873\n",
      "10m 2s (- 23m 24s) (15000 30%) 2.7951\n",
      "13m 24s (- 20m 6s) (20000 40%) 2.0665\n",
      "16m 36s (- 16m 36s) (25000 50%) 1.4143\n",
      "19m 49s (- 13m 12s) (30000 60%) 0.9878\n",
      "23m 7s (- 9m 54s) (35000 70%) 0.6573\n",
      "26m 33s (- 6m 38s) (40000 80%) 0.4366\n",
      "30m 5s (- 3m 20s) (45000 90%) 0.2920\n",
      "33m 41s (- 0m 0s) (50000 100%) 0.2136\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "losses = trainIters(encoder = encoder1, decoder = attn_decoder1, n_iters = 50000, print_every=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> do you really think we can help ?\n",
      "= 너 진짜 우리가 도울 수 있을 거라고 생각해 .\n",
      "< 너 진짜 우리가 도울 수 있을 거라고 생각해 . <EOS>\n",
      "\n",
      "> i ll kill him .\n",
      "= 나는 그를 죽일 것이다 .\n",
      "< 나는 그를 죽일 것이다 . <EOS>\n",
      "\n",
      "> sorry but you can t go in there .\n",
      "= 미안한데, 거기 들어오면 안 돼 .\n",
      "< 미안한데, 거기 들어오면 안 돼 . <EOS>\n",
      "\n",
      "> tom is a family oriented person .\n",
      "= 톰은 가정 중심적인 사람이야 .\n",
      "< 톰은 가정 중심적인 사람이야 . <EOS>\n",
      "\n",
      "> does anybody here know how this thing works ?\n",
      "= 이걸 어떻게 하는지 아는 사람 .\n",
      "< 이걸 어떻게 하는지 아는 사람 . <EOS>\n",
      "\n",
      "> i m feeling really confident now .\n",
      "= 난 지금 자신감에 넘치고 있어 .\n",
      "< 난 지금 자신감에 넘치고 있어 . <EOS>\n",
      "\n",
      "> we talked .\n",
      "= 우린 서로 얘기했어 .\n",
      "< 우린 서로 얘기했어 . <EOS>\n",
      "\n",
      "> nothing could sway his conviction .\n",
      "= 그 어떤 것도 그의 신념을 꺾을 수 없었다 .\n",
      "< 그 어떤 것도 그의 신념을 꺾을 수 없었다 . <EOS>\n",
      "\n",
      "> i shook tom awake .\n",
      "= 난 톰을 흔들어 깨웠어 .\n",
      "< 난 톰을 흔들어 깨웠어 . <EOS>\n",
      "\n",
      "> i caught a cold .\n",
      "= 감기에 걸렸어 .\n",
      "< 감기에 걸렸어 . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 th test-------------------------------\n",
      "\n",
      "input sentence : it was a rhetorical question .\n",
      "target sentence : 이건 수사적인 질문이었어 .\n",
      "output sentence : 이건 수사적인 질문이었어 . <EOS>\n",
      "\n",
      "\n",
      "------------ Attention -------------\n",
      "이건 <- a\n",
      "수사적인 <- rhetorical\n",
      "질문이었어 <- question\n",
      ". <- .\n",
      "<EOS> <- it\n",
      "\n",
      "\n",
      "2 th test-------------------------------\n",
      "\n",
      "input sentence : everything stopped .\n",
      "target sentence : 모든 것이 멈췄어 .\n",
      "output sentence : 모든 것이 멈췄어 . <EOS>\n",
      "\n",
      "\n",
      "------------ Attention -------------\n",
      "모든 <- .\n",
      "<EOS> <- .\n",
      "\n",
      "\n",
      "3 th test-------------------------------\n",
      "\n",
      "input sentence : i don t sleep a lot .\n",
      "target sentence : 나는 많이 자지 않아요 .\n",
      "output sentence : 나는 잠이 많지 않아요 . <EOS>\n",
      "\n",
      "\n",
      "------------ Attention -------------\n",
      "나는 <- t\n",
      "잠이 <- sleep\n",
      "많지 <- a\n",
      "않아요 <- a\n",
      ". <- .\n",
      "<EOS> <- t\n",
      "\n",
      "\n",
      "4 th test-------------------------------\n",
      "\n",
      "input sentence : it works .\n",
      "target sentence : 작동하네 .\n",
      "output sentence : 되네 . <EOS>\n",
      "\n",
      "\n",
      "------------ Attention -------------\n",
      "되네 <- .\n",
      "<EOS> <- it\n",
      "\n",
      "\n",
      "5 th test-------------------------------\n",
      "\n",
      "input sentence : tom is a very dedicated actor .\n",
      "target sentence : 톰은 아주 헌신적인 배우야 .\n",
      "output sentence : 톰은 아주 헌신적인 배우야 . <EOS>\n",
      "\n",
      "\n",
      "------------ Attention -------------\n",
      "톰은 <- a\n",
      "아주 <- very\n",
      "헌신적인 <- dedicated\n",
      "배우야 <- actor\n",
      ". <- .\n",
      "<EOS> <- a\n",
      "\n",
      "\n",
      "6 th test-------------------------------\n",
      "\n",
      "input sentence : tom is ashamed of his body .\n",
      "target sentence : 톰은 자기 몸을 창피해하고 있어 .\n",
      "output sentence : 톰은 자기 몸을 창피해하고 있어 . <EOS>\n",
      "\n",
      "\n",
      "------------ Attention -------------\n",
      "톰은 <- ashamed\n",
      "자기 <- of\n",
      "몸을 <- of\n",
      "있어 <- .\n",
      "<EOS> <- ashamed\n",
      "\n",
      "\n",
      "7 th test-------------------------------\n",
      "\n",
      "input sentence : beef please .\n",
      "target sentence : 쇠고기요 .\n",
      "output sentence : 좀더 큰소리로 부탁해 . <EOS>\n",
      "\n",
      "\n",
      "------------ Attention -------------\n",
      "좀더 <- .\n",
      "<EOS> <- beef\n",
      "\n",
      "\n",
      "8 th test-------------------------------\n",
      "\n",
      "input sentence : please sit .\n",
      "target sentence : 제발 앉아 .\n",
      "output sentence : 앉아 줘 . <EOS>\n",
      "\n",
      "\n",
      "------------ Attention -------------\n",
      "앉아 <- .\n",
      "<EOS> <- .\n",
      "\n",
      "\n",
      "9 th test-------------------------------\n",
      "\n",
      "input sentence : is this wine ?\n",
      "target sentence : 이게 와인이야 .\n",
      "output sentence : 이게 와인이야 . <EOS>\n",
      "\n",
      "\n",
      "------------ Attention -------------\n",
      "이게 <- wine\n",
      "와인이야 <- ?\n",
      "<EOS> <- ?\n",
      "\n",
      "\n",
      "10 th test-------------------------------\n",
      "\n",
      "input sentence : don t lie . be honest .\n",
      "target sentence : 거짓말 하지 말고, 솔직해져 봐 .\n",
      "output sentence : 거짓말 하지 말고, 솔직해져 봐 . <EOS>\n",
      "\n",
      "\n",
      "------------ Attention -------------\n",
      "거짓말 <- lie\n",
      "하지 <- .\n",
      "말고, <- be\n",
      "솔직해져 <- don\n",
      "봐 <- don\n",
      "<EOS> <- lie\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10) : \n",
    "    pair = random.choice(pairs)\n",
    "    eng = pair[0]\n",
    "    kor = pair[1] \n",
    "    output_words, attentions = evaluate(encoder1, attn_decoder1, eng)\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    print(\"\\n\")\n",
    "    print(\"%d th test-------------------------------\\n\" %(_+1))\n",
    "    print(\"input sentence : \" + eng)\n",
    "    print(\"target sentence : \" + kor)\n",
    "    print(\"output sentence : \" + output_sentence)\n",
    "    eng = eng.split(' ')\n",
    "    print(\"\\n\")\n",
    "    print(\"------------ Attention -------------\")\n",
    "    for i in range(len(attentions)) :\n",
    "        attention_score = attentions[i]\n",
    "        _ , idx = attention_score.topk(1)\n",
    "        if idx[0].item() < len(eng):\n",
    "            print(\"%s <- %s\" %(output_words[i], eng[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 th test-------------------------------\n",
      "\n",
      "input sentence : tom is very dedicated man .\n",
      "output sentence : 톰은 아마 나한테 하모니카를 프랑스어를 가르쳤어 . <EOS>\n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "eng = 'tom is very dedicated man .'\n",
    "output_words, attentions = evaluate(encoder1, attn_decoder1, eng)\n",
    "output_sentence = ' '.join(output_words)\n",
    "print(\"\\n\")\n",
    "print(\"%d th test-------------------------------\\n\" %(_+1))\n",
    "print(\"input sentence : \" + eng)\n",
    "print(\"output sentence : \" + output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tom currently lives alone in a small apartment .', '탐은 현재 작은 아파트에서 혼자 살고 있다 .']\n"
     ]
    }
   ],
   "source": [
    "print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
